"""
ReAct ìŠ¤íƒ€ì¼ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ LangChain Tools ì •ì˜

ì´ íŒŒì¼ì˜ í•¨ìˆ˜ë“¤ì€ @tool ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” íˆ´ë¡œ ë“±ë¡ë©ë‹ˆë‹¤.

** ReAct íŒ¨í„´ì—ì„œì˜ íˆ´ ì—­í•  **
LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , í•„ìš”ì‹œ ììœ¨ì ìœ¼ë¡œ ì´ íˆ´ë“¤ì„ í˜¸ì¶œí•˜ì—¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

** ì œê³µë˜ëŠ” íˆ´ë“¤ **
1. list_departments: í•™ê³¼ ëª©ë¡ ì¡°íšŒ
2. get_universities_by_department: íŠ¹ì • í•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ì¡°íšŒ
3. get_major_career_info: ì „ê³µë³„ ì§„ì¶œ ì§ì—…/ë¶„ì•¼ ì¡°íšŒ
4. get_search_help: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì‚¬ìš© ê°€ì´ë“œ ì œê³µ

** ì‘ë™ ë°©ì‹ **
1. LLMì´ ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„
2. LLMì´ í•„ìš”í•œ íˆ´ ì„ íƒ ë° íŒŒë¼ë¯¸í„° ê²°ì •
3. íˆ´ ì‹¤í–‰ (ì´ íŒŒì¼ì˜ í•¨ìˆ˜ í˜¸ì¶œ)
4. íˆ´ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì „ë‹¬
5. LLMì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
"""

from typing import List, Dict, Any, Optional, Tuple
from langchain_core.tools import tool
import re
import json
from backend.config import get_llm
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from .vectorstore import get_university_majors_vectorstore
from .university_lookup import lookup_university_url, search_universities

# ==================== ìƒìˆ˜ ì •ì˜ ====================

# ê²€ìƒ‰ ê²°ê³¼ ì œí•œ
DEFAULT_SEARCH_LIMIT = 10
MAX_UNIVERSITY_RESULTS = 200
UNIVERSITY_PREVIEW_COUNT = 5
VECTOR_SEARCH_MULTIPLIER = 3

# ì¶œë ¥ í¬ë§·
SEPARATOR_LINE = "=" * 80


# ==================== ë¡œê¹… ìœ í‹¸ë¦¬í‹° ====================


def _log_tool_start(tool_name: str, description: str) -> None:
    """
    íˆ´ ì‹¤í–‰ ì‹œì‘ ë¡œê·¸ ì¶œë ¥

    Args:
        tool_name: íˆ´ ì´ë¦„
        description: ì‹¤í–‰ ëª©ì  ì„¤ëª…
    """
    print(f"[Tool:{tool_name}] ì‹œì‘ - {description}")


def _log_tool_result(tool_name: str, outcome: str) -> None:
    """
    íˆ´ ì‹¤í–‰ ê²°ê³¼ ë¡œê·¸ ì¶œë ¥

    Args:
        tool_name: íˆ´ ì´ë¦„
        outcome: ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
    """
    print(f"[Tool:{tool_name}] ê²°ê³¼ - {outcome}")


# ==================== ì‚¬ìš©ì ê°€ì´ë“œ ====================


def _get_tool_usage_guide() -> str:
    """
    ì‚¬ìš©ìì—ê²Œ ì œê³µí•  íˆ´ ì‚¬ìš© ê°€ì´ë“œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
        ê²€ìƒ‰ ê°€ëŠ¥í•œ ë°©ë²•ë“¤ì„ ì„¤ëª…í•˜ëŠ” ê°€ì´ë“œ ë©”ì‹œì§€
    """
    return """
ğŸ¤– **Major Mentor ê²€ìƒ‰ ê°€ì´ë“œ**

ì €í¬ëŠ” **ì „êµ­ ëŒ€í•™ì˜ ì „ê³µ ì •ë³´, ê°œì„¤ ëŒ€í•™, ê·¸ë¦¬ê³  ì¡¸ì—… í›„ ì§„ë¡œ ë°ì´í„°**ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤! 
ê¶ê¸ˆí•œ ì ì„ ì•„ë˜ì™€ ê°™ì´ ë¬¼ì–´ë³´ì‹œë©´ ìì„¸íˆ ë‹µë³€í•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.

### 1ï¸âƒ£ **ì „ê³µ íƒìƒ‰**
ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ë‚˜ í‚¤ì›Œë“œë¡œ ì–´ë–¤ í•™ê³¼ë“¤ì´ ìˆëŠ”ì§€ ì°¾ì•„ë³´ì„¸ìš”.
- "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ í•™ê³¼ ì•Œë ¤ì¤˜"
- "ê³µí•™ ê³„ì—´ì—ëŠ” ì–´ë–¤ ì „ê³µì´ ìˆì–´?"
- "ê²½ì˜í•™ê³¼ë‘ ë¹„ìŠ·í•œ í•™ê³¼ ì¶”ì²œí•´ì¤˜"

### 2ï¸âƒ£ **ê°œì„¤ ëŒ€í•™ ì°¾ê¸°**
íŠ¹ì • í•™ê³¼ê°€ ì–´ëŠ ëŒ€í•™ì— ê°œì„¤ë˜ì–´ ìˆëŠ”ì§€ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.
- "ì»´í“¨í„°ê³µí•™ê³¼ê°€ ìˆëŠ” ëŒ€í•™ ì–´ë””ì•¼?"
- "ì„œìš¸ì— ìˆëŠ” ì‹¬ë¦¬í•™ê³¼ ì•Œë ¤ì¤˜"
- "ê°„í˜¸í•™ê³¼ ê°œì„¤ ëŒ€í•™ ëª©ë¡ ë³´ì—¬ì¤˜"

### 3ï¸âƒ£ **ì§„ë¡œ ë° ìƒì„¸ ì •ë³´**
ì¡¸ì—… í›„ ì–´ë–¤ ì§ì—…ì„ ê°–ê²Œ ë˜ëŠ”ì§€, ì—°ë´‰ì´ë‚˜ í•„ìš”í•œ ìê²©ì¦ì€ ë¬´ì—‡ì¸ì§€ í™•ì¸í•´ë³´ì„¸ìš”.
- "ì»´í“¨í„°ê³µí•™ê³¼ ë‚˜ì˜¤ë©´ ë¬´ìŠ¨ ì¼ í•´?"
- "ê¸°ê³„ê³µí•™ê³¼ ì¡¸ì—… í›„ ì—°ë´‰ì€ ì–¼ë§ˆì•¼?"
- "ì‚¬íšŒë³µì§€í•™ê³¼ ê°€ë ¤ë©´ ì–´ë–¤ ìê²©ì¦ì´ í•„ìš”í•´?"
- "ê²½ì˜í•™ê³¼ì—ì„œëŠ” ì£¼ë¡œ ë­˜ ë°°ì›Œ?"

### 4ï¸âƒ£ **ë§ì¶¤ ì „ê³µ ì¶”ì²œ**
ê°„ë‹¨í•œ ì§ˆë¬¸ì— ë‹µí•˜ê³  ë‚˜ì—ê²Œ ë”± ë§ëŠ” ì „ê³µì„ ì¶”ì²œë°›ì•„ë³´ì„¸ìš”!
- **"ì¶”ì²œ ì‹œì‘"** ì´ë¼ê³  ì…ë ¥í•˜ë©´ ì¶”ì²œ ê³¼ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤.

ğŸ’¡ **íŒ**: ì§ˆë¬¸ì´ êµ¬ì²´ì ì¼ìˆ˜ë¡ ë” ì •í™•í•œ ì •ë³´ë¥¼ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
"""


# ==================== í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° ====================


def _strip_html(value: str) -> str:
    """
    HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜

    Args:
        value: HTMLì´ í¬í•¨ëœ ë¬¸ìì—´

    Returns:
        HTML íƒœê·¸ê°€ ì œê±°ëœ ìˆœìˆ˜ í…ìŠ¤íŠ¸
    """
    return re.sub(r"<[^>]+>", " ", value or "")


def _normalize_major_key(value: str) -> str:
    """
    ì „ê³µëª…ì„ ì •ê·œí™”í•˜ì—¬ ë¹„êµ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    ê³µë°± ì œê±° ë° ì†Œë¬¸ì ë³€í™˜

    Args:
        value: ì›ë³¸ ì „ê³µëª…

    Returns:
        ì •ê·œí™”ëœ ì „ê³µëª… (ê³µë°± ì œê±°, ì†Œë¬¸ì)
    """
    return re.sub(r"\s+", "", (value or "").lower())


def _dedup_preserve_order(items: List[str]) -> List[str]:
    """
    ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ë˜ ìˆœì„œëŠ” ìœ ì§€

    Args:
        items: ì¤‘ë³µì´ í¬í•¨ëœ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì¤‘ë³µì´ ì œê±°ëœ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ (ìˆœì„œ ìœ ì§€)
    """
    seen: set[str] = set()
    ordered: List[str] = []
    for item in items:
        if item and item not in seen:
            seen.add(item)
            ordered.append(item)
    return ordered


# ==================== ì „ê³µ ì¹´í…Œê³ ë¦¬ ê´€ë¦¬ ====================


def _load_major_categories() -> Dict[str, List[str]]:
    """
    DB(MajorCategory)ì—ì„œ ì „ê³µ ë¶„ë¥˜ ì •ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    from backend.db.connection import SessionLocal
    from backend.db.models import MajorCategory

    session = SessionLocal()
    categories = {}
    try:
        results = session.query(MajorCategory).all()
        for row in results:
            if row.major_names:
                try:
                    # JSON ë¬¸ìì—´ íŒŒì‹±
                    loaded_list = json.loads(row.major_names)
                    if isinstance(loaded_list, list):
                        categories[row.category_name] = loaded_list
                except json.JSONDecodeError:
                    pass

        if not categories:
            print("âš ï¸ Major categories not found in DB.")

        return categories
    except Exception as e:
        print(f"âš ï¸ Failed to load major categories from DB: {e}")
        return {}
    finally:
        session.close()


# ì „ê³µ ì¹´í…Œê³  ìºì‹± ë³€ìˆ˜ (Late Binding)
_MAIN_CATEGORIES: Optional[Dict[str, List[str]]] = None


def get_main_categories() -> Dict[str, List[str]]:
    """
    ì „ê³µ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ë¡œë“œí•˜ê³  ìºì‹±í•©ë‹ˆë‹¤. (Lazy Loading)
    ìµœì´ˆ í˜¸ì¶œ ì‹œ DBì—ì„œ ë¡œë“œí•˜ë©°, ì‹¤íŒ¨ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global _MAIN_CATEGORIES
    if _MAIN_CATEGORIES is None:
        _MAIN_CATEGORIES = _load_major_categories()
    return _MAIN_CATEGORIES


def _expand_category_query(query: str) -> Tuple[List[str], str]:
    """
    list_departmentsìš© ì¿¼ë¦¬ í™•ì¥ í•¨ìˆ˜

    ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ í† í°ê³¼ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜:
    - ëŒ€ë¶„ë¥˜(key)ë¥¼ ë„£ìœ¼ë©´: í•´ë‹¹ keyì— ì†í•œ ëª¨ë“  ì„¸ë¶€ valueë“¤ì„ í’€ì–´ì„œ í‚¤ì›Œë“œë¡œ ì‚¬ìš©
    - ì„¸ë¶€ ë¶„ë¥˜(value)ë¥¼ ë„£ìœ¼ë©´: "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥" â†’ ["ì»´í“¨í„°","ì†Œí”„íŠ¸ì›¨ì–´","ì¸ê³µì§€ëŠ¥"]
    - ê·¸ ì™¸ ì¼ë°˜ í…ìŠ¤íŠ¸: "/", "," ê¸°ì¤€ìœ¼ë¡œ í† í° ë‚˜ëˆˆ ë’¤ ì‚¬ìš©

    Args:
        query: ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬

    Returns:
        (tokens, embed_text) íŠœí”Œ
        - tokens: ê²€ìƒ‰ì— ì‚¬ìš©í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        - embed_text: ë²¡í„° ì„ë² ë”©ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸
    """
    raw = query.strip()
    if not raw:
        return [], ""

    categories = get_main_categories()
    tokens: List[str] = []

    # 1) ëŒ€ë¶„ë¥˜(key) ì…ë ¥ì¸ ê²½ìš° â†’ í•´ë‹¹ keyì˜ ëª¨ë“  ì„¸ë¶€ valueë¥¼ í•œêº¼ë²ˆì— í’€ì–´ì„œ ì‚¬ìš©
    if raw in categories:
        details = categories[raw]
        for item in details:
            # "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥" í˜•íƒœë¥¼ ê°œë³„ í† í°ìœ¼ë¡œ ë¶„ë¦¬
            parts = [p.strip() for p in re.split(r"[\/,()]", item) if p.strip()]
            tokens.extend(parts)

    # 2) ì„¸ë¶€ ë¶„ë¥˜(value) ê·¸ëŒ€ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°
    elif any(raw in v for values in categories.values() for v in values):
        parts = [p.strip() for p in re.split(r"[\/,()]", raw) if p.strip()]
        tokens.extend(parts)

    # 3) ì¼ë°˜ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ (ì˜ˆ: "ì»´í“¨í„° / ì†Œí”„íŠ¸ì›¨ì–´ / ì¸ê³µì§€ëŠ¥", "AI, ë°ì´í„°")
    else:
        parts = [p.strip() for p in re.split(r"[\/,]", raw) if p.strip()]
        if parts:
            tokens.extend(parts)
        else:
            tokens.append(raw)

    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
    dedup_tokens = _dedup_preserve_order(tokens)

    # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±
    embed_text = " ".join(dedup_tokens) if dedup_tokens else raw

    return dedup_tokens, embed_text


# ==================== ì „ê³µ ë°ì´í„° ê´€ë¦¬ (DB ê¸°ë°˜) ====================

from backend.db.connection import SessionLocal
from backend.db.models import Major


def _convert_db_model_to_record(row: Major) -> Any:
    """DB ëª¨ë¸ ê°ì²´ë¥¼ MajorRecord ë°ì´í„°í´ë˜ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    from backend.rag.loader import MajorRecord  # ìˆœí™˜ ì°¸ì¡° ë°©ì§€

    # ì°¨íŠ¸ ë°ì´í„°ì—ì„œ ì„±ë¹„/ë§Œì¡±ë„ ì¶”ì¶œ
    gender = None
    satisfaction = None

    chart_data_obj = json.loads(row.chart_data) if row.chart_data else None
    if chart_data_obj and isinstance(chart_data_obj, list):
        stats_block = chart_data_obj[0]
        if isinstance(stats_block, dict):
            gender = stats_block.get("gender")
            satisfaction = stats_block.get("satisfaction")

    aliases = json.loads(row.department_aliases) if row.department_aliases else []

    return MajorRecord(
        major_id=row.major_id,
        major_name=row.major_name,
        cluster=None,
        summary=row.summary or "",
        interest=row.interest or "",
        property=row.property or "",
        relate_subject=json.loads(row.relate_subject) if row.relate_subject else None,
        job=row.job or "",
        enter_field=json.loads(row.enter_field) if row.enter_field else None,
        salary=row.salary,
        employment=row.employment,
        employment_rate=row.employment_rate,
        acceptance_rate=row.acceptance_rate,
        department_aliases=aliases,
        career_act=json.loads(row.career_act) if row.career_act else None,
        qualifications=row.qualifications,
        main_subject=json.loads(row.main_subject) if row.main_subject else None,
        university=json.loads(row.university) if row.university else None,
        chart_data=chart_data_obj,
        raw=json.loads(row.raw_data) if row.raw_data else {},
        gender=gender,
        satisfaction=satisfaction,
    )


def _lookup_major_by_name(query: str) -> Optional[Any]:
    """
    ì •í™•í•œ ì „ê³µëª… ë˜ëŠ” ë³„ì¹­ìœ¼ë¡œ ì „ê³µ ì •ë³´ë¥¼ DBì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤. (Exact Match Only)
    """
    query_str = query.strip()
    if not query_str:
        return None

    session = SessionLocal()
    try:
        # 1. ì „ê³µëª… ì •í™• ì¼ì¹˜
        obj = session.query(Major).filter(Major.major_name == query_str).first()

        # 2. ë³„ì¹­ ê²€ìƒ‰ (ì „ê³µëª… ì¼ì¹˜ê°€ ì—†ì„ ê²½ìš°)
        if not obj:
            # JSON ë¦¬ìŠ¤íŠ¸ ë‚´ ê²€ìƒ‰ (LIKE ì‚¬ìš©)
            search_pattern = f'%"{query_str}"%'
            obj = (
                session.query(Major)
                .filter(Major.department_aliases.like(search_pattern))
                .first()
            )

        if obj:
            return _convert_db_model_to_record(obj)
        return None
    finally:
        session.close()


def _filter_majors_by_token(token: str, limit: int = DEFAULT_SEARCH_LIMIT) -> List[Any]:
    """
    ì „ê³µëª…ì— íŠ¹ì • í† í°(í‚¤ì›Œë“œ)ì´ í¬í•¨ëœ ì „ê³µë“¤ì„ DBì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤. (Partial Match)
    """
    token_str = token.strip()
    if not token_str:
        return []

    session = SessionLocal()
    try:
        results = (
            session.query(Major)
            .filter(Major.major_name.like(f"%{token_str}%"))
            .limit(limit)
            .all()
        )
        return [_convert_db_model_to_record(obj) for obj in results]
    finally:
        session.close()


def _search_major_records_by_vector(
    query: str, limit: int = DEFAULT_SEARCH_LIMIT
) -> List[Any]:
    """
    ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ìœ ì‚¬í•œ ì „ê³µì„ ì°¾ê³ , DBì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    from backend.rag.embeddings import get_embeddings
    from backend.rag.retriever import search_major_docs, aggregate_major_scores

    embeddings = get_embeddings()
    query_vec = embeddings.embed_query(query)

    # top_këŠ” limit * VECTOR_SEARCH_MULTIPLIERë¡œ ì—¬ìœ ìˆê²Œ ê°€ì ¸ì˜´
    hits = search_major_docs(query_vec, top_k=limit * VECTOR_SEARCH_MULTIPLIER)

    # ì ìˆ˜ ì§‘ê³„
    aggregated_scores = aggregate_major_scores(
        hits, doc_type_weights={"summary": 1.2, "subjects": 0.8, "jobs": 0.8}
    )

    # ìƒìœ„ major_id ì¶”ì¶œ
    sorted_majors = sorted(aggregated_scores.items(), key=lambda x: x[1], reverse=True)[
        :limit
    ]
    top_ids = [mid for mid, score in sorted_majors]

    if not top_ids:
        return []

    session = SessionLocal()
    try:
        records = []
        majors = session.query(Major).filter(Major.major_id.in_(top_ids)).all()
        major_map = {m.major_id: m for m in majors}

        for mid in top_ids:
            if mid in major_map:
                records.append(_convert_db_model_to_record(major_map[mid]))

        return records
    finally:
        session.close()


def _search_university_majors_by_vector(
    query: str, limit: int = 5
) -> List[Dict[str, Any]]:
    """
    ëŒ€í•™-í•™ê³¼ ë‹¨ìœ„ë¡œ ì„¸ë°€í•˜ê²Œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (Namespace: university_majors)
    """
    try:
        vs = get_university_majors_vectorstore()
        # threshold=0.75 ì´ìƒë§Œ ë¦¬í„´í•˜ë„ë¡ ì„¤ì •
        docs = vs.similarity_search_with_score(query, k=limit * 2)

        results = []
        for doc, score in docs:
            if score < 0.75:
                continue

            results.append(
                {
                    "university": doc.metadata.get("university"),
                    "department": doc.metadata.get("department"),
                    "major_name": doc.metadata.get("major_name"),  # ëŒ€ë¶„ë¥˜ ì´ë¦„
                    "major_id": doc.metadata.get("major_id"),  # ëŒ€ë¶„ë¥˜ ID
                    "score": score,
                }
            )

        # ëŒ€í•™ëª…+í•™ê³¼ëª… ì¤‘ë³µ ì œê±° (ì ìˆ˜ ë†’ì€ ìˆœ ìœ ì§€)
        deduped = []
        seen = set()
        for res in results:
            key = f"{res['university']}-{res['department']}"
            if key not in seen:
                seen.add(key)
                deduped.append(res)

        return deduped[:limit]
    except Exception as e:
        print(f"âš ï¸ University major search failed: {e}")
        return []


def _verify_with_llm(
    query: str, candidates: List[Dict[str, Any]]
) -> Optional[Dict[str, Any]]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ëª¨í˜¸í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ê°€ì¥ ì ì ˆí•œ ëŒ€í•™-í•™ê³¼ í›„ë³´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    """
    if not candidates:
        return None

    # í›„ë³´êµ°ì´ 1ê°œì´ê³  ì ìˆ˜ê°€ ë§¤ìš° ë†’ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜ (Token ì ˆì•½)
    if len(candidates) == 1 and candidates[0]["score"] > 0.88:
        return candidates[0]

    # í›„ë³´êµ° í¬ë§·íŒ…
    candidates_text = ""
    for idx, c in enumerate(candidates):
        candidates_text += f"{idx + 1}. {c['university']} {c['department']} (Category: {c['major_name']})\n"

    prompt = ChatPromptTemplate.from_template("""
    User Query: {query}
    
    Candidates:
    {candidates}
    
    Which candidate is the best match for the user's query?
    If the user explicitly mentions a university, prioritize that university.
    If multiple candidates are valid (e.g. same department in different campuses), pick the first valid one.
    If none are good matches, return 0.
    
    Return ONLY the number of the best match.
    """)

    try:
        llm = get_llm()
        chain = prompt | llm | StrOutputParser()
        result = chain.invoke({"query": query, "candidates": candidates_text})

        # ìˆ«ìë§Œ ì¶”ì¶œ
        match_idx = int(re.sub(r"\D", "", result.strip()) or "0") - 1
        if 0 <= match_idx < len(candidates):
            _log_tool_result(
                "LLM Verification",
                f"Selected: {candidates[match_idx]['university']} {candidates[match_idx]['department']}",
            )
            return candidates[match_idx]
    except Exception as e:
        print(f"âš ï¸ LLM verification failed: {e}")

    return None


def _find_majors(query: str, limit: int = DEFAULT_SEARCH_LIMIT) -> List[Any]:
    """
    í†µí•© ì „ê³µ ê²€ìƒ‰ í•¨ìˆ˜ (4ë‹¨ê³„ ê²€ìƒ‰ ì „ëµ - DB ê¸°ë°˜)

    1. ì •í™•í•œ ì „ê³µëª… ë§¤ì¹­
    2. ë³„ì¹­ ë§¤ì¹­
    3. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í•­ìƒ ìˆ˜í–‰)
    4. í† í° í•„í„°ë§ (ë³´ì™„)
    """
    matches: List[Any] = []
    seen_ids: set[str] = set()

    # 0ë‹¨ê³„: ëŒ€í•™-í•™ê³¼ ì •ë°€ ê²€ìƒ‰ (New Granular Search)
    univ_matches = _search_university_majors_by_vector(query, limit=5)

    best_univ_match = None
    if univ_matches:
        # LLMì—ê²Œ ê²€ì¦ ìš”ì²­
        verification_result = _verify_with_llm(query, univ_matches)
        if verification_result:
            best_univ_match = verification_result
        elif len(univ_matches) > 0 and univ_matches[0]["score"] > 0.82:
            # LLMì´ ì‹¤íŒ¨í–ˆê±°ë‚˜ 0ì„ ë°˜í™˜í–ˆë”ë¼ë„, ì ìˆ˜ê°€ ë†’ìœ¼ë©´ 1ìˆœìœ„ ì‚¬ìš©
            best_univ_match = univ_matches[0]

    if best_univ_match:
        # ì •ë°€ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ëŒ€ë¶„ë¥˜ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì¶”ê°€
        direct_univ = _lookup_major_by_name(best_univ_match["major_name"])
        if direct_univ:
            matches.append(direct_univ)
            seen_ids.add(direct_univ.major_id)
            print(
                f"âœ¨ Granular Match Found: {best_univ_match['university']} {best_univ_match['department']}"
            )

    # 1ë‹¨ê³„: ì •í™•í•œ ì „ê³µëª… ë§¤ì¹­
    direct = _lookup_major_by_name(query)
    if direct and direct.major_id not in seen_ids:
        matches.append(direct)
        seen_ids.add(direct.major_id)

    # ì¿¼ë¦¬ í™•ì¥
    tokens, embed_text = _expand_category_query(query)

    # 2ë‹¨ê³„: ë³„ì¹­ ê²€ìƒ‰ (í† í° ê¸°ë°˜)
    if not matches and tokens:
        for token in tokens:
            alias_match = _lookup_major_by_name(token)
            if alias_match and alias_match.major_id not in seen_ids:
                matches.append(alias_match)
                seen_ids.add(alias_match.major_id)

    # 3ë‹¨ê³„: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í•­ìƒ ìˆ˜í–‰)
    search_text = embed_text or query
    vector_matches = _search_major_records_by_vector(
        search_text, limit=max(limit, DEFAULT_SEARCH_LIMIT)
    )

    for record in vector_matches:
        if record.major_id not in seen_ids:
            matches.append(record)
            seen_ids.add(record.major_id)
        if len(matches) >= limit:
            break

    # 4ë‹¨ê³„: í† í° í•„í„°ë§ (ë³´ì™„)
    if len(matches) < limit and tokens:
        for token in tokens:
            token_matches = _filter_majors_by_token(token, limit=limit)
            for record in token_matches:
                if record.major_id not in seen_ids:
                    matches.append(record)
                    seen_ids.add(record.major_id)
                if len(matches) >= limit:
                    break
            if len(matches) >= limit:
                break

    return matches[:limit]


# ==================== ëŒ€í•™ ì •ë³´ ì¶”ì¶œ ====================


def _extract_university_entries(record: Any) -> List[Dict[str, str]]:
    """
    MajorRecordì—ì„œ ëŒ€í•™ ì •ë³´ ì¶”ì¶œ

    Args:
        record: MajorRecord ê°ì²´

    Returns:
        ëŒ€í•™ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        [
            {
                "university": "ì„œìš¸ëŒ€í•™êµ",
                "college": "ê³µê³¼ëŒ€í•™",
                "department": "ì»´í“¨í„°ê³µí•™ê³¼",
                "area": "ì„œìš¸",
                "campus": "ë³¸êµ",
                "url": "https://...",
                "standard_major_name": "ì»´í“¨í„°ê³µí•™"
            },
            ...
        ]
    """
    entries: List[Dict[str, str]] = []
    raw_list = getattr(record, "university", None)

    if not isinstance(raw_list, list):
        return entries

    seen: set[Tuple[str, str, str]] = set()

    for item in raw_list:
        # í•„ë“œ ì¶”ì¶œ
        school = (item.get("schoolName") or "").strip()
        campus = (item.get("campus_nm") or item.get("campusNm") or "").strip()
        major_name = (item.get("majorName") or "").strip()
        area = (item.get("area") or "").strip()
        url = (item.get("schoolURL") or "").strip()

        # ëŒ€í•™ëª…ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not school:
            continue

        # [BugFix] Hallucination ë°©ì§€:
        # JSON ë°ì´í„°ì— majorNameì´ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°, ì´ê²ƒì€ í•´ë‹¹ ëŒ€í•™ì˜ íŠ¹ì • í•™ê³¼ê°€ ì•„ë‹ˆë¼
        # 'ì¼ë°˜ì ì¸ í•™ê³¼ ì •ë³´'ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
        # ë”°ë¼ì„œ majorNamgì´ ë¹„ì–´ìˆìœ¼ë©´ record.major_name(ëŒ€í‘œ í•™ê³¼ëª…)ì„ ì“°ë˜,
        # ì´ë¥¼ 'ëŒ€í•™ì˜ ì‹¤ì œ í•™ê³¼'ë¡œ í™•ì • ì§“ëŠ” ê²ƒì„ ì‹ ì¤‘íˆ í•´ì•¼ í•©ë‹ˆë‹¤.
        # ë‹¤ë§Œ, í˜„ì¬ ë¡œì§ìƒ ëŒ€í•™ ëª©ë¡ì„ ë³´ì—¬ì¤˜ì•¼ í•˜ë¯€ë¡œ record.major_nameì„ ì“°ë˜
        # ë‚˜ì¤‘ì— í•„í„°ë§ í•  ìˆ˜ ìˆë„ë¡ í•¨.
        # ì—¬ê¸°ì„œëŠ” major_nameì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„ í•˜ê³ , ì—†ìœ¼ë©´ record.major_nameì„ ì”ë‹ˆë‹¤.
        # í•˜ì§€ë§Œ, major_nameì´ ì‹¤ì œë¡œ ë¹„ì–´ìˆëŠ” ê²½ìš°(ëŒ€í•™ í…Œì´ë¸”ì—ë§Œ ë§¤í•‘ëœ ê²½ìš°)
        # ì‚¬ìš©ìê°€ "í•œì–‘ëŒ€ ì»´ê³µ"ì´ë¼ê³  ë¬¼ì—ˆì„ ë•Œ "í•œì–‘ëŒ€ ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€"ê°€ ë‚˜ì™€ì•¼ í•˜ëŠ”ë°
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ "í•œì–‘ëŒ€ ì»´í“¨í„°ê³µí•™(í‘œì¤€)"ìœ¼ë¡œ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ.

        dept_label = major_name
        if not dept_label:
            # majorNameì´ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µí•˜ê±°ë‚˜, í‘œì¤€ ì´ë¦„ì„ ì‚¬ìš©í•˜ë˜ í‘œì‹œ
            # ì—¬ê¸°ì„œëŠ” ì—„ê²©í•˜ê²Œ majorNameì´ ìˆëŠ” ê²½ìš°ë§Œ ìœ íš¨í•œ 'ê°œì„¤ í•™ê³¼'ë¡œ ë´…ë‹ˆë‹¤.
            # ë°ì´í„° í’ˆì§ˆì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ Hallucination ë°©ì§€ë¥¼ ìœ„í•´ ì—„ê²© ëª¨ë“œ ì ìš©
            # ë§Œì•½ ë°ì´í„°ê°€ ì „ë¶€ majorNameì´ ë¹„ì–´ìˆë‹¤ë©´ ì´ ë¡œì§ì€ ìˆ˜ì • í•„ìš”.
            # ì¼ë‹¨ì€ í‘œì¤€ ì´ë¦„ ì‚¬ìš©í•˜ë˜, ì›ë³¸ ë°ì´í„°ê°€ ì—†ì—ˆìŒì„ ì¸ì§€.
            dept_label = record.major_name

        # ì¤‘ë³µ ì œê±°
        dedup_key = (school, dept_label, campus)
        if dedup_key in seen:
            continue
        seen.add(dedup_key)

        entry: Dict[str, str] = {
            "university": school,
            "college": campus or area or "",
            "department": dept_label,
        }

        if area:
            entry["area"] = area
        if campus:
            entry["campus"] = campus
        if url:
            entry["url"] = url

        # í‘œì¤€ í•™ê³¼ëª…ê³¼ ë‹¤ë¥´ë©´ ê¸°ë¡
        if record.major_name and record.major_name != dept_label:
            entry["standard_major_name"] = record.major_name

        entries.append(entry)

    return entries


def _collect_university_pairs(record: Any, limit: int = 3) -> List[str]:
    """
    ì „ê³µ ë ˆì½”ë“œì—ì„œ "ëŒ€í•™ëª… í•™ê³¼ëª…" í˜•íƒœì˜ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ ìƒì„±

    Args:
        record: MajorRecord ê°ì²´
        limit: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜

    Returns:
        "ëŒ€í•™ëª… í•™ê³¼ëª…" í˜•íƒœì˜ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
        ì˜ˆ: ["ì„œìš¸ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼", "ì—°ì„¸ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼", ...]
    """
    entries = _extract_university_entries(record)
    pairs: List[str] = []

    for entry in entries[:limit]:
        university = entry.get("university", "").strip()
        department = entry.get("department", "").strip()

        # ëŒ€í•™ëª…ê³¼ í•™ê³¼ëª…ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°
        label = " ".join(token for token in [university, department] if token)

        if label and label not in pairs:
            pairs.append(label)

    return pairs


def _get_majors_for_university(university_name: str) -> List[str]:
    """
    íŠ¹ì • ëŒ€í•™ì— ê°œì„¤ëœ ëª¨ë“  í•™ê³¼ ëª©ë¡ì„ ë°˜í™˜
    (ê³µë°± ì œì™¸ ë¶€ë¶„ ì¼ì¹˜ë¡œ ëŒ€í•™ ì‹ë³„)
    """
    target_clean = university_name.replace(" ", "").strip()
    if not target_clean:
        return []

    majors = set()
    session = SessionLocal()
    try:
        # JSON ë¬¸ìì—´ ê²€ìƒ‰ (LIKE)
        # university ì»¬ëŸ¼ì— í•´ë‹¹ ëŒ€í•™ ì´ë¦„ì´ í¬í•¨ëœ ë ˆì½”ë“œë§Œ ì¡°íšŒ
        # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¡°íšŒí•  ìˆ˜ë„ ìˆì§€ë§Œ, _extract_university_entriesê°€ ì „ì²´ recordë¥¼ ì”€
        # university_nameì´ í¬í•¨ëœ ëŒ€ëµì ì¸ í›„ë³´êµ° ì¡°íšŒ
        candidates = (
            session.query(Major)
            .filter(Major.university.like(f"%{target_clean}%"))
            .all()
        )

        for row in candidates:
            # DB ëª¨ë¸ -> Record ë³€í™˜ (í•„ìš”í•œ í•„ë“œë§Œ ìˆì–´ë„ ë¨)
            record = _convert_db_model_to_record(row)
            entries = _extract_university_entries(record)
            for entry in entries:
                univ = entry.get("university", "")
                if target_clean in univ.replace(" ", ""):
                    dept = entry.get("department")
                    if dept:
                        majors.add(dept)

        return sorted(list(majors))
    finally:
        session.close()


# ==================== ì§„ë¡œ ì •ë³´ ì¶”ì¶œ ====================


def _extract_job_list(job_text: str) -> List[str]:
    """
    ì§„ì¶œ ì§ì—… í…ìŠ¤íŠ¸ë¥¼ ê°œë³„ ì§ì—…ëª… ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬

    Args:
        job_text: ì‰¼í‘œ/ìŠ¬ë˜ì‹œ/ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ëœ ì§ì—…ëª… ë¬¸ìì—´

    Returns:
        ì¤‘ë³µì´ ì œê±°ëœ ì§ì—…ëª… ë¦¬ìŠ¤íŠ¸
    """
    if not job_text:
        return []

    # êµ¬ë¶„ìë¡œ ë¶„ë¦¬
    parts = re.split(r"[,/\n]", job_text)

    # ê³µë°± ì œê±° ë° ë„ˆë¬´ ì§§ì€ í•­ëª© ì œì™¸
    cleaned = [part.strip() for part in parts if len(part.strip()) > 1]

    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
    return _dedup_preserve_order(cleaned)


def _format_enter_field(record: Any) -> List[Dict[str, str]]:
    """
    major_detail.jsonì˜ enter_field êµ¬ì¡°ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì •ë¦¬

    Args:
        record: MajorRecord ê°ì²´

    Returns:
        ì§„ì¶œ ë¶„ì•¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        [
            {"category": "ê¸°ì—… ë° ì‚°ì—…ì²´", "description": "..."},
            {"category": "ì—°êµ¬ì†Œ", "description": "..."},
            ...
        ]
    """
    formatted: List[Dict[str, str]] = []
    raw_list = getattr(record, "enter_field", None)

    if not isinstance(raw_list, list):
        return formatted

    for item in raw_list:
        if not isinstance(item, dict):
            continue

        # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (ì˜¤íƒ€ ëŒ€ì‘: gradeuate/graduate)
        category = (item.get("gradeuate") or item.get("graduate") or "").strip()
        description = _strip_html(item.get("description") or "").strip()

        # ì¹´í…Œê³ ë¦¬ì™€ ì„¤ëª…ì´ ëª¨ë‘ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not category and not description:
            continue

        entry: Dict[str, str] = {}
        if category:
            entry["category"] = category
        if description:
            entry["description"] = description

        formatted.append(entry)

    return formatted


def _format_career_activities(record: Any) -> List[Dict[str, str]]:
    """
    í•™ê³¼ ì¤€ë¹„ í™œë™(career_act)ì„ act_name/description ì§ìœ¼ë¡œ ì •ë¦¬

    Args:
        record: MajorRecord ê°ì²´

    Returns:
        ì¶”ì²œ í™œë™ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        [
            {"act_name": "ê±´ì¶•ë°•ëŒíšŒ", "act_description": "..."},
            {"act_name": "ì½”ë”©ëŒ€íšŒ", "act_description": "..."},
            ...
        ]
    """
    activities: List[Dict[str, str]] = []
    raw_list = getattr(record, "career_act", None)

    if not isinstance(raw_list, list):
        return activities

    for item in raw_list:
        if not isinstance(item, dict):
            continue

        name = (item.get("act_name") or "").strip()
        description = _strip_html(item.get("act_description") or "").strip()

        # ì´ë¦„ê³¼ ì„¤ëª…ì´ ëª¨ë‘ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not name and not description:
            continue

        entry: Dict[str, str] = {}
        if name:
            entry["act_name"] = name
        if description:
            entry["act_description"] = description

        activities.append(entry)

    return activities


def _parse_qualifications(record: Any) -> Tuple[str, List[str]]:
    """
    qualifications í•„ë“œë¥¼ ë¬¸ìì—´/ë¦¬ìŠ¤íŠ¸ ì—¬ë¶€ì— ê´€ê³„ì—†ì´ ì¼ê´€ëœ í˜•íƒœë¡œ ë³€í™˜

    Args:
        record: MajorRecord ê°ì²´

    Returns:
        (joined_text, list) íŠœí”Œ
        - joined_text: ì‰¼í‘œë¡œ ì—°ê²°ëœ ìê²©ì¦ ë¬¸ìì—´
        - list: ê°œë³„ ìê²©ì¦ ë¦¬ìŠ¤íŠ¸
    """
    raw_value = getattr(record, "qualifications", None)

    if raw_value is None:
        return "", []

    tokens: List[str] = []

    # ë¦¬ìŠ¤íŠ¸ íƒ€ì… ì²˜ë¦¬
    if isinstance(raw_value, list):
        tokens = [str(item).strip() for item in raw_value if str(item).strip()]
    # ë¬¸ìì—´ íƒ€ì… ì²˜ë¦¬
    else:
        text = str(raw_value).strip()
        if text:
            parts = [p.strip() for p in re.split(r"[,/\n]", text) if p.strip()]
            tokens = parts

    # ì¤‘ë³µ ì œê±°
    deduped = _dedup_preserve_order(tokens)

    # ì‰¼í‘œë¡œ ì—°ê²°
    joined = ", ".join(deduped)

    return joined, deduped


def _format_main_subjects(record: Any) -> List[Dict[str, str]]:
    """
    main_subject ë°°ì—´ì—ì„œ ê³¼ëª©ëª…ê³¼ ìš”ì•½ì„ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬

    Args:
        record: MajorRecord ê°ì²´

    Returns:
        ì£¼ìš” ê³¼ëª© ì •ë³´ ë¦¬ìŠ¤íŠ¸
        [
            {"SBJECT_NM": "ê±´ì¶•êµ¬ì¡°ì‹œìŠ¤í…œ", "SBJECT_SUMRY": "..."},
            {"SBJECT_NM": "ê±´ì¶•ì„¤ê³„", "SBJECT_SUMRY": "..."},
            ...
        ]
    """
    subjects: List[Dict[str, str]] = []
    raw_list = getattr(record, "main_subject", None)

    if not isinstance(raw_list, list):
        return subjects

    for item in raw_list:
        if not isinstance(item, dict):
            continue

        # ê³¼ëª©ëª… ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ ì´ë¦„ ì§€ì›)
        name = (item.get("SBJECT_NM") or item.get("subject_name") or "").strip()
        summary = _strip_html(
            item.get("SBJECT_SUMRY") or item.get("subject_description") or ""
        ).strip()

        # ê³¼ëª©ëª…ê³¼ ìš”ì•½ì´ ëª¨ë‘ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not name and not summary:
            continue

        entry: Dict[str, str] = {}
        if name:
            entry["SBJECT_NM"] = name
        if summary:
            entry["SBJECT_SUMRY"] = summary

        subjects.append(entry)

    return subjects


def _resolve_major_for_career(query: str) -> Optional[Any]:
    """
    ì§„ë¡œ ì •ë³´ ì¡°íšŒë¥¼ ìœ„í•œ ì „ê³µ ë ˆì½”ë“œ ê²€ìƒ‰

    Args:
        query: ì „ê³µëª… ë˜ëŠ” ë³„ì¹­

    Returns:
        ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ MajorRecord ê°ì²´ ë˜ëŠ” None
    """
    if not query:
        return None

    # _find_majorsë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì „ê³µ 1ê°œ ë°˜í™˜
    matches = _find_majors(query, limit=1)
    return matches[0] if matches else None


# ==================== ì¶œë ¥ í¬ë§·íŒ… ====================


def _format_department_output(
    query: str,
    departments: List[str],
    total_available: Optional[int] = None,
    dept_univ_map: Optional[Dict[str, List[str]]] = None,
) -> str:
    """
    í•™ê³¼ ëª©ë¡ì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ í¬ë§·íŒ…

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        departments: í•™ê³¼ëª… ë¦¬ìŠ¤íŠ¸
        total_available: ì „ì²´ í•™ê³¼ ìˆ˜ (ì„ íƒ)
        dept_univ_map: í•™ê³¼ë³„ ê°œì„¤ ëŒ€í•™ ë§¤í•‘ (ì„ íƒ)

    Returns:
        í¬ë§·íŒ…ëœ í•™ê³¼ ëª©ë¡ ë¬¸ìì—´
    """
    lines = []

    # í—¤ë”
    lines.append(SEPARATOR_LINE)
    lines.append(f"ğŸ¯ ê²€ìƒ‰ ê²°ê³¼: '{query}'ì— ëŒ€í•œ í•™ê³¼ {len(departments)}ê°œ")
    if total_available is not None:
        lines.append(f"(ì´ {total_available}ê°œ ì¤‘ ìƒìœ„ {len(departments)}ê°œ í‘œì‹œ)")
    lines.append(SEPARATOR_LINE)
    lines.append("")
    lines.append("ğŸ“‹ **ì •í™•í•œ í•™ê³¼ëª… ëª©ë¡** (ì•„ë˜ ë°±í‹± ì•ˆì˜ ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì„¸ìš”):")
    lines.append("")

    # í•™ê³¼ ëª©ë¡
    for i, dept in enumerate(departments, 1):
        lines.append(f"{i}. `{dept}`")

        # ê°œì„¤ ëŒ€í•™ ì˜ˆì‹œ ì¶”ê°€
        if dept_univ_map:
            universities = dept_univ_map.get(dept)
            if universities:
                lines.append(f"   - ê°œì„¤ ëŒ€í•™ ì˜ˆì‹œ: {', '.join(universities)}")

    return "\n".join(lines)


# ==================== ëŒ€í™” ê¸°ë¡ ìš”ì•½ ====================
def _format_conversation_history(history: List[Dict[str, str]]) -> str:
    """
    ëŒ€í™” ê¸°ë¡ì„ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

    Args:
        history: ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸ (ê° í•­ëª©ì€ {"role": "user"/"assistant", "content": "ë©”ì‹œì§€ ë‚´ìš©"} í˜•íƒœ)

    Returns:
        í¬ë§·íŒ…ëœ ëŒ€í™” ê¸°ë¡ ë¬¸ìì—´
    """
    lines = []
    # ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…
    for turn in history:
        # ì—­í• ê³¼ ë‚´ìš© ì¶”ì¶œ
        role = turn.get("role", "user")
        content = turn.get("content", "").strip()

        # ì—­í• ì— ë”°ë¼ ì ‘ë‘ì‚¬ ì¶”ê°€
        if role == "user":
            lines.append(f"User: {content}")
        else:
            lines.append(f"Assistant: {content}")
    return "\n".join(lines)


def summarize_conversation_history(history: List[Dict[str, str]]) -> str:
    """
    ëŒ€í™” ê¸°ë¡ì„ ìš”ì•½í•˜ì—¬ ê°„ê²°í•œ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        history: ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸ (ê° í•­ëª©ì€ {"role": "user"/"assistant", "content": "ë©”ì‹œì§€ ë‚´ìš©"} í˜•íƒœ)

    Returns:
        ìš”ì•½ëœ ëŒ€í™” ê¸°ë¡ ë¬¸ìì—´
    """
    llm = get_llm()

    prompt = ChatPromptTemplate.from_template("""
    ë‹¤ìŒì€ ì‚¬ìš©ìì™€ AIì˜ ëŒ€í™” ê¸°ë¡ì´ë‹¤.
    ì´ ëŒ€í™”ë¥¼ ì‚¬ìš©ìê°€ ë‚˜ì¤‘ì— ë‹¤ì‹œ ë³¼ ë•Œ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•´ë¼.

    âš ï¸ ì£¼ì˜:
    - ëŒ€í™” ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ë‚˜ì—´í•˜ì§€ ë§ ê²ƒ
    - User / Assistant í˜•ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
    - "ì‚¬ìš©ìëŠ”", "AIëŠ”" ê°™ì€ 3ì¸ì¹­ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
    - ê°œê´„ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•  ê²ƒ
        - "-í•¨", "-ì„", ì²´ì–¸ ì¢…ê²° ë“± ëª…ì‚¬í˜• í‘œí˜„ ì‚¬ìš©
        - "-í–ˆë‹¤", "-ì´ë‹¤" ê°™ì€ ì„œìˆ í˜•ë³´ë‹¤ëŠ” ì§§ê³  ê°„ê²°í•œ í‘œí˜„ ì„ í˜¸
    - ë‹¨, ê²°ë¡  ë¶€ë¶„ë§Œ ì˜ˆì™¸ì ìœ¼ë¡œ ì¹œê·¼í•œ êµ¬ì–´ì²´ ì‚¬ìš©
        - "-í•´ë³´ë©´ ì¢‹ê² ì–´ìš”", "-ì¶”ì²œë“œë ¤ìš”", "-í™•ì¸í•´ë³´ì„¸ìš”" ë“±
    - í•µì‹¬ë§Œ ì¶”ë ¤ í•˜ë‚˜ì˜ ìš”ì•½ë¬¸ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ

    ### ìš”ì•½ í˜•ì‹: ###
    [í‚¤ì›Œë“œ ì¶”ì¶œì„ í†µí•´ íƒœê·¸/ì¹´í…Œê³ ë¦¬ ìë™ ìƒì„±]
    #ì§„ë¡œìƒë‹´ #í•™ê³¼ì¶”ì²œ #ì• ë‹ˆë©”ì´ì…˜ #ì˜ˆì²´ëŠ¥
                                              
    í•µì‹¬ ì£¼ì œ
    - [í•œ ë¬¸ì¥ìœ¼ë¡œ ëŒ€í™”ì˜ ë©”ì¸ í† í”½ ì„¤ëª…]

    ì£¼ìš” ë‚´ìš©
    - [ì¤‘ìš”í–ˆë˜ í¬ì¸íŠ¸ 2-3ê°œ]
    - [êµ¬ì²´ì ì¸ ì •ë³´ë‚˜ ì¶”ì²œ ë‚´ìš© í¬í•¨]

    ê²°ë¡ 
    - [ë„ì¶œëœ ê²°ë¡ ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì œì•ˆí•˜ë“¯ì´]
                                              
    ëŒ€í™” í†µê³„
    - ì´ ë©”ì‹œì§€: nê°œ
    - ì£¼ìš” í† í”½: nê°œ (ì–´ë–¤ í† í”½ì¸ì§€)
                                              
    ëŒ€í™” ê¸°ë¡:
    {conversation_history}
    """)

    chain = prompt | llm | StrOutputParser()
    history_text = _format_conversation_history(history)
    result = chain.invoke({"conversation_history": history_text})
    return result.strip()


# ==================== LangChain Tools ====================


@tool
def list_departments(query: str, top_k: int = DEFAULT_SEARCH_LIMIT) -> str:
    """
    Pinecone majors vector DBë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ê³¼ ëª©ë¡ì„ ì¡°íšŒí•˜ê³  ì¶”ì²œí•˜ëŠ” íˆ´ì…ë‹ˆë‹¤.

    ì´ íˆ´ì„ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” ìƒí™© (LLMìš© ê°€ì´ë“œ):
    - ì‚¬ìš©ìê°€
      - "ì–´ë–¤ í•™ê³¼ë“¤ì´ ìˆì–´?", "ì»´í“¨í„° ê´€ë ¨ í•™ê³¼ ì•Œë ¤ì¤˜"
      - "ë‚˜ì˜ ê´€ì‹¬ì‚¬ëŠ” ~ì¸ë° ì–´ë–¤ ì „ê³µì´ ì¢‹ì„ê¹Œ?" (ê´€ì‹¬ì‚¬ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰)
      - "~ì™€ ë¹„ìŠ·í•œ ì „ê³µ ì¶”ì²œí•´ì¤˜"
      ì™€ ê°™ì´ **ì „ê³µ/í•™ê³¼ ëª©ë¡ íƒìƒ‰**ì„ ìš”ì²­í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    - íŠ¹ì • í•™ê³¼ì˜ ìƒì„¸ ì •ë³´(ì§„ë¡œ, ì—°ë´‰ ë“±)ë‚˜ ê°œì„¤ ëŒ€í•™ì„ ë¬»ëŠ” ì§ˆë¬¸ì—ëŠ” ì´ íˆ´ì´ ì•„ë‹ˆë¼
      `get_major_career_info`ë‚˜ `get_universities_by_department`ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

    íŒŒë¼ë¯¸í„° ì„¤ëª…:
    - query:
        ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì „ê³µ ë¶„ì•¼, ê´€ì‹¬ì‚¬ í‚¤ì›Œë“œ, ë˜ëŠ” "ì „ì²´".
        ì˜ˆ: "ì¸ê³µì§€ëŠ¥", "ë¡œë´‡", "ê²½ì˜", "ì „ì²´"
    - top_k:
        ë°˜í™˜í•  í•™ê³¼ ê°œìˆ˜. ê¸°ë³¸ê°’ì€ 10ì…ë‹ˆë‹¤.
    """
    raw_query = (query or "").strip()
    _log_tool_start(
        "list_departments",
        f"í•™ê³¼ ëª©ë¡ ì¡°íšŒ - query='{raw_query or 'ì „ì²´'}', top_k={top_k}",
    )
    print(f"âœ… Using list_departments tool with query: '{raw_query}'")

    raw_query = (query or "").strip()
    _log_tool_start(
        "list_departments",
        f"í•™ê³¼ ëª©ë¡ ì¡°íšŒ - query='{raw_query or 'ì „ì²´'}', top_k={top_k}",
    )
    print(f"âœ… Using list_departments tool with query: '{raw_query}'")

    # ì „ì²´ ëª©ë¡ ìš”ì²­ ì²˜ë¦¬
    if raw_query == "ì „ì²´" or not raw_query:
        dept_univ_map: Dict[str, List[str]] = {}
        all_names = []

        session = SessionLocal()
        try:
            # ëª¨ë“  ì „ê³µ ì¡°íšŒ (top_kê°€ í¬ì§€ ì•Šë‹¤ë©´ limit ì ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, ì „ì²´ í†µê³„ê°€ í•„ìš”í•˜ë©´ ë‹¤ ê°€ì ¸ì˜´)
            # ì—¬ê¸°ì„œëŠ” top_k ì œí•œì„ ê±¸ì–´ì„œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì„±ëŠ¥ìƒ ìœ ë¦¬í•¨
            query_obj = session.query(Major)

            # ì „ì²´ ê°œìˆ˜ ì¹´ìš´íŠ¸
            total_count = query_obj.count()

            # ì´ë¦„ìˆœ ì •ë ¬í•˜ì—¬ top_kë§Œí¼ ê°€ì ¸ì˜¤ê¸° (í˜¹ì€ ì „ì²´ ê°€ì ¸ì™€ì„œ í¬ë§·íŒ…?)
            # ì—¬ê¸°ì„œëŠ” ë¡œì§ ìœ ì§€: ì „ì²´ ì´ë¦„ì„ ìˆ˜ì§‘í•˜ê³  ì •ë ¬
            # í•˜ì§€ë§Œ DBì—ì„œ Order By í•˜ëŠ”ê²Œ ë‚«ë‹¤.
            # limit ì—†ì´ ë‹¤ ê°€ì ¸ì˜¤ëŠ”ê±´ ìœ„í—˜í•˜ë¯€ë¡œ ì•ˆì „ì¥ì¹˜ë¡œ 500ê°œ ì œí•œ
            fetched_majors = query_obj.order_by(Major.major_name).limit(500).all()

            for row in fetched_majors:
                record = _convert_db_model_to_record(row)
                if not record.major_name:
                    continue

                all_names.append(record.major_name)

                # ê°œì„¤ ëŒ€í•™ ì •ë³´ ìˆ˜ì§‘
                pairs = _collect_university_pairs(record)
                if pairs:
                    bucket = dept_univ_map.setdefault(record.major_name, [])
                    for pair in pairs:
                        if pair not in bucket:
                            bucket.append(pair)

        finally:
            session.close()

        # ì •ë ¬ ë° ì œí•œ
        # DBì—ì„œ ì´ë¯¸ ì •ë ¬í–ˆì§€ë§Œ, ì¤‘ë³µ ì œê±° ë“± íŒŒì´ì¬ ë¡œì§ ìœ ì§€
        all_names = sorted(set(all_names))
        limited = all_names[:top_k] if top_k else all_names

        print(
            f"âœ… Returning {len(limited)} majors out of {len(all_names)} total (DB limited 500)"
        )

        result_text = _format_department_output(
            raw_query or "ì „ì²´",
            limited,
            total_available=total_count,  # ì‹¤ì œ DB ì¹´ìš´íŠ¸ ì‚¬ìš©
            dept_univ_map=dept_univ_map,
        )

        _log_tool_result(
            "list_departments", f"ì´ {len(all_names)}ê°œ ì¤‘ {len(limited)}ê°œ ëª©ë¡ ë°˜í™˜"
        )
        return result_text

    # í‚¤ì›Œë“œ ê²€ìƒ‰ ì²˜ë¦¬
    tokens, embed_text = _expand_category_query(raw_query)
    print(f"   â„¹ï¸ Expanded query tokens: {tokens}")
    print(f"   â„¹ï¸ Embedding text: '{embed_text}'")

    # í†µí•© ê²€ìƒ‰ ì‹¤í–‰
    matches = _find_majors(raw_query, limit=max(top_k, DEFAULT_SEARCH_LIMIT))
    dept_univ_map: Dict[str, List[str]] = {}

    # ê° ë§¤ì¹­ëœ ì „ê³µì˜ ê°œì„¤ ëŒ€í•™ ì •ë³´ ìˆ˜ì§‘
    for record in matches:
        pairs = _collect_university_pairs(record)
        if pairs:
            bucket = dept_univ_map.setdefault(record.major_name, [])
            for pair in pairs:
                if pair not in bucket:
                    bucket.append(pair)

    # í•™ê³¼ëª… ë¦¬ìŠ¤íŠ¸ ìƒì„±
    department_names = [record.major_name for record in matches if record.major_name]

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if not department_names:
        print("âš ï¸  WARNING: No majors found for the given query")
        _log_tool_result("list_departments", "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."

    # ê²°ê³¼ ì œí•œ ë° í¬ë§·íŒ…
    result = department_names[:top_k]
    print(f"âœ… Returning {len(result)} majors from major_detail vector DB")

    _log_tool_result("list_departments", f"{len(result)}ê°œ í•™ê³¼ ì •ë³´ ë°˜í™˜")
    result_text = _format_department_output(
        raw_query, result, dept_univ_map=dept_univ_map
    )

    # [UX] 3ê¸€ì ì´í•˜ì˜ ë‹¨ì¶•ì–´ ì‚¬ìš© ì‹œ íŒ ì œê³µ
    if len(raw_query) <= 3:
        tip_msg = f"\n\nğŸ’¡ Tip: '{raw_query}' ê°™ì€ ì¤„ì„ë§ë³´ë‹¤ëŠ” 'ì»´í“¨í„°ê³µí•™ê³¼'ì²˜ëŸ¼ ì •ì‹ ëª…ì¹­ìœ¼ë¡œ ê²€ìƒ‰í•˜ë©´ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ìˆì–´ìš”!"
        result_text += tip_msg

    return result_text


@tool
def get_major_career_info(
    major_name: str, specific_field: str = "all"
) -> Dict[str, Any]:
    """
    íŠ¹ì • ì „ê³µì˜ ìƒì„¸ ì •ë³´(ì§„ë¡œ, ì·¨ì—…ë¥ , ì—°ë´‰, ê´€ë ¨ ìê²©ì¦ ë“±)ë¥¼ ì¡°íšŒí•˜ëŠ” íˆ´ì…ë‹ˆë‹¤.

    [ì¤‘ìš”: ì¼ë°˜ ì •ë³´ ì›ì¹™]
    - ì´ íˆ´ì€ **íŠ¹ì • ëŒ€í•™ì˜ ë°ì´í„°ê°€ ì•„ë‹Œ, êµ­ê°€ í‘œì¤€(ì»¤ë¦¬ì–´ë„·) ë°ì´í„°**ë§Œ ì œê³µí•©ë‹ˆë‹¤.
    - ì‚¬ìš©ìê°€ íŠ¹ì • ëŒ€í•™ê³¼ í•™ê³¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ë¬¼ì–´ë³´ë©´, ì´ íˆ´ì„ ì‚¬ìš©í•˜ë˜ **ê²°ê³¼ë¥¼ ì„¤ëª…í•  ë•Œ ì ˆëŒ€ íŠ¹ì • ëŒ€í•™ì˜ ì •ë³´ì¸ ê²ƒì²˜ëŸ¼ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.**
    - "í•œì–‘ëŒ€ ì»´í“¨í„°ê³µí•™ê³¼ì˜ ì·¨ì—…ë¥ ì€..." (X) -> "í•œì–‘ëŒ€í•™êµì˜ êµ¬ì²´ì ì¸ ì·¨ì—…ë¥  ê³µì‹œ ìë£ŒëŠ” ì—†ìœ¼ë‚˜, êµ­ê°€ í‘œì¤€ ë°ì´í„°ì— ë”°ë¥¸ ì¼ë°˜ì ì¸ ì»´í“¨í„°ê³µí•™ê³¼ì˜ ì·¨ì—…ë¥ ì€..." (O)

    [í˜¸ì¶œ ì‹œì ]
    - **ì·¨ì—…ë¥ , ì—°ë´‰, ì§„ë¡œ, ì¡¸ì—… í›„ ì§ì—…** ê´€ë ¨ ì§ˆë¬¸ì€ ëŒ€í•™ëª…ì´ í¬í•¨ë˜ì–´ ìˆì–´ë„ ë¬´ì¡°ê±´ ì´ íˆ´ì„ ì‚¬ìš©í•˜ì„¸ìš”.
    - ì…ë ¥ìœ¼ë¡œ ë°›ì€ ëŒ€í•™ëª…ì€ ë¬´ì‹œí•˜ê³  **í•™ê³¼ëª…ë§Œ** ì‚¬ìš©í•˜ì„¸ìš”.

    íŒŒë¼ë¯¸í„° ì„¤ëª…:
    - major_name: ì •ë³´ë¥¼ ì¡°íšŒí•  í•™ê³¼ëª…. (ì˜ˆ: "ì»´í“¨í„°ê³µí•™ê³¼")
    - specific_field:
        ì‚¬ìš©ìê°€ ê¶ê¸ˆí•´í•˜ëŠ” íŠ¹ì • ì •ë³´ë¥¼ ì§€ì •í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë§Œ ê°€ì ¸ë³´ì„¸ìš”.
        - "jobs": ì§„ì¶œ ì§ì—…, ê´€ë ¨ ì§ì—… ë¦¬ìŠ¤íŠ¸, ì§„ì¶œ ë¶„ì•¼
        - "stats": ì·¨ì—…ë¥ , ì…í•™ ê²½ìŸë¥ , ë‚¨ë…€ ì„±ë¹„, ë§Œì¡±ë„, ì¡¸ì—… í›„ ì—°ë´‰
        - "academics": ì£¼ìš” êµê³¼ëª©, ê´€ë ¨ ìê²©ì¦, í•™ê³¼ ê´€ë ¨ í™œë™
        - "all": (ê¸°ë³¸ê°’) ìœ„ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•œ ì „ì²´ ìš”ì•½

    [í•„ìˆ˜ ì²˜ë¦¬]
    - ê²°ê³¼ì— `warning_context`ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ë‹µë³€ ì‹œ **ë°˜ë“œì‹œ í•´ë‹¹ ê²½ê³  ë¬¸êµ¬**ë¥¼ í¬í•¨í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê³ ì§€í•˜ì„¸ìš”.
    """
    query = (major_name or "").strip()
    field = (specific_field or "all").lower()

    _log_tool_start(
        "get_major_career_info", f"ì „ê³µ ì •ë³´ ì¡°íšŒ - major='{query}', field='{field}'"
    )
    print(f"âœ… Using get_major_career_info tool for: '{query}' (Field: {field})")

    # ì…ë ¥ ê²€ì¦
    if not query:
        return {
            "error": "invalid_query",
            "message": "ì „ê³µëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
            "suggestion": "ì˜ˆ: 'ì»´í“¨í„°ê³µí•™ê³¼', 'ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™ê³¼'",
        }

    # ì „ê³µ ë ˆì½”ë“œ ê²€ìƒ‰
    record = _resolve_major_for_career(query)
    if record is None:
        print(f"âš ï¸  WARNING: No career data found for '{query}'")
        return {
            "error": "no_results",
            "message": f"'{query}' ì „ê³µì˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "suggestion": "í•™ê³¼ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ê±°ë‚˜ list_departments íˆ´ë¡œ ì „ê³µëª…ì„ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.",
        }

    # ì‘ë‹µ êµ¬ì„± (ê³µí†µ í•„ë“œ)
    response: Dict[str, Any] = {
        "major": record.major_name,
        "source": "backend/data/major_detail.json",
        "warning_context": (
            "âš ï¸ [ì¹˜ëª…ì  ê²½ê³ ] ì´ ì •ë³´ëŠ” íŠ¹ì • ëŒ€í•™ì˜ ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤. "
            "ë°˜ë“œì‹œ 'ì»¤ë¦¬ì–´ë„·'ì˜ [êµ­ê°€ í‘œì¤€ ë°ì´í„°]ì„ì„ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. "
            "ë‹µë³€ ì‹œ 'OOëŒ€í•™êµì˜ ìë£ŒëŠ” ì•„ë‹ˆì§€ë§Œ, ì¼ë°˜ì ì¸ OOí•™ê³¼ì˜ ì •ë³´ì— ë”°ë¥´ë©´...'ì´ë¼ëŠ” ë¬¸êµ¬ë¥¼ í•„ìˆ˜ì ìœ¼ë¡œ í¬í•¨í•˜ì„¸ìš”."
        ),
        "data_source_disclaimer": "ë³¸ ë°ì´í„°ëŠ” ëŒ€í•™ë³„ ê°œë³„ ê³µì‹œ ìë£Œê°€ ì•„ë‹Œ, ì»¤ë¦¬ì–´ë„·ì˜ í‘œì¤€ í•™ê³¼ ì •ë³´ì…ë‹ˆë‹¤.",
    }

    # 1. ì§ì—…/ì§„ë¡œ ì •ë³´ (jobs)
    if field in ["all", "jobs"]:
        job_text = (getattr(record, "job", "") or "").strip()
        job_list = _extract_job_list(job_text)
        enter_field = _format_enter_field(record)

        response["jobs"] = job_list
        response["job_summary"] = job_text
        response["enter_field"] = enter_field

        if not job_list:
            response["warning"] = "ë°ì´í„°ì— ë“±ë¡ëœ ì§ì—… ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        else:
            print(f"   â„¹ï¸ Included {len(job_list)} jobs")

    # 2. í†µê³„ ì •ë³´ (stats)
    if field in ["all", "stats"]:
        # ì—°ë´‰ ì •ë³´ ê³„ì‚° (ì›”í‰ê·  * 12)
        annual_salary = None
        if record.salary:
            try:
                annual_salary = float(record.salary) * 12
            except (ValueError, TypeError):
                pass

        response["gender_ratio"] = record.gender
        response["satisfaction"] = record.satisfaction
        response["employment_rate"] = record.employment_rate
        response["acceptance_rate"] = record.acceptance_rate
        response["annual_salary"] = annual_salary
        print(
            f"   â„¹ï¸ Included stats (employment: {record.employment_rate}, salary: {annual_salary})"
        )

    # 3. í•™ì—…/ìê²©ì¦/í™œë™ ì •ë³´ (academics)
    if field in ["all", "academics"]:
        career_activities = _format_career_activities(record)
        qualifications_text, qualifications_list = _parse_qualifications(record)
        main_subjects = _format_main_subjects(record)

        if career_activities:
            response["career_act"] = career_activities
        if qualifications_text:
            response["qualifications"] = qualifications_text
        if qualifications_list:
            response["qualifications_list"] = qualifications_list
        if main_subjects:
            response["main_subject"] = main_subjects

        print(
            f"   â„¹ï¸ Included academic info (subjects: {len(main_subjects)}, acts: {len(career_activities)})"
        )

    _log_tool_result(
        "get_major_career_info", f"{record.major_name} ì •ë³´ ë°˜í™˜ (Field: {field})"
    )

    return response


@tool
def get_universities_by_department(department_name: str) -> List[Dict[str, str]]:
    """
    íŠ¹ì • í•™ê³¼ë¥¼ ê°œì„¤í•œ ëŒ€í•™ ëª©ë¡ì„ ì¡°íšŒí•˜ëŠ” íˆ´ì…ë‹ˆë‹¤.

    ì´ íˆ´ì„ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” ìƒí™© (LLMìš© ê°€ì´ë“œ):
    - ì‚¬ìš©ìê°€
      - "ì»´í“¨í„°ê³µí•™ê³¼ëŠ” ì–´ëŠ ëŒ€í•™ì— ìˆì–´?"
      - "ì„œìš¸ì— ìˆëŠ” ì‹¬ë¦¬í•™ê³¼ ëŒ€í•™ ì•Œë ¤ì¤˜"
      - "ê³ ë¶„ìê³µí•™ê³¼ ê°œì„¤ ëŒ€í•™ ë³´ì—¬ì¤˜"
      ì™€ ê°™ì´ **íŠ¹ì • í•™ê³¼ì˜ ê°œì„¤ ëŒ€í•™ ì •ë³´**ë¥¼ ìš”ì²­í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.

    íŒŒë¼ë¯¸í„° ì„¤ëª…:
    - department_name:
        ëŒ€í•™ ëª©ë¡ì„ ì°¾ê³  ì‹¶ì€ í•™ê³¼ëª….
        ì˜ˆ: "ì»´í“¨í„°ê³µí•™ê³¼", "ì‹¬ë¦¬í•™ê³¼"
    """
    query = (department_name or "").strip()
    _log_tool_start(
        "get_universities_by_department", f"í•™ê³¼ë³„ ëŒ€í•™ ì¡°íšŒ - department='{query}'"
    )
    print(f"âœ… Using get_universities_by_department tool for: '{query}'")

    # ì…ë ¥ ê²€ì¦
    if not query:
        result = [
            {
                "error": "invalid_query",
                "message": "í•™ê³¼ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
                "suggestion": "ì˜ˆ: 'ì»´í“¨í„°ê³µí•™ê³¼', 'ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€'",
            }
        ]
        _log_tool_result("get_universities_by_department", "í•™ê³¼ëª… ëˆ„ë½ - ì˜¤ë¥˜ ë°˜í™˜")
        return result

    from backend.db.connection import get_db
    from backend.db.models import Major
    import json

    db = next(get_db())
    aggregated: List[Dict[str, str]] = []
    seen = set()

    try:
        # =========================================================
        # 1. Vector DB Semantic Search (ì˜ë¯¸ ê¸°ë°˜ ëŒ€ë¶„ë¥˜ í™•ì¥)
        # =========================================================
        vector_matched_names = []
        try:
            from backend.rag.vectorstore import get_major_category_vectorstore

            vectorstore = get_major_category_vectorstore()
            # ê²€ìƒ‰ì–´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í•™ê³¼ëª… ìƒìœ„ 20ê°œ ê²€ìƒ‰
            docs = vectorstore.similarity_search(query, k=20)

            vector_matched_names = [d.page_content for d in docs]
            print(f"Vector Search found related categories: {vector_matched_names}")
        except Exception as e:
            print(f"   âš ï¸  Vector Search failed: {e}")

        # =========================================================
        # 2. SQL í‚¤ì›Œë“œ ê²€ìƒ‰ (ê¸°ë³¸)
        # =========================================================
        # 2-1. 1ì°¨ ê²€ìƒ‰: ì •í™•í•œ í¬í•¨ (LIKE %query%)
        major_records = (
            db.query(Major).filter(Major.major_name.like(f"%{query}%")).all()
        )
        print(f"Primary Search found {len(major_records)} records")

        # 2-2. 2ì°¨ ê²€ìƒ‰: ì ‘ë¯¸ì‚¬ ì œê±° í›„ í™•ì¥ (Keyword Expansion)
        normalized_query = _normalize_major_key(query)
        keyword = (
            normalized_query.replace("í•™ê³¼", "").replace("ì „ê³µ", "").replace("ë¶€", "")
        )

        if len(keyword) >= 2 and keyword != query:
            print(f"Expanding search with keyword: '{keyword}'")
            secondary_records = (
                db.query(Major).filter(Major.major_name.like(f"%{keyword}%")).all()
            )
            print(f"Secondary Search found {len(secondary_records)} records")

            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ê¸°ì¡´ ë ˆì½”ë“œì— ì¶”ê°€
            existing_ids = {r.id for r in major_records}
            for sr in secondary_records:
                if sr.id not in existing_ids:
                    major_records.append(sr)
                    existing_ids.add(sr.id)

        # 2-3. [New] Vector ë§¤ì¹­ ê²°ê³¼ ì¶”ê°€ (Semantic Expansion)
        if vector_matched_names:
            print(f"Applying Vector matches: {vector_matched_names}")
            # vector_matched_namesì— ìˆëŠ” 'í‘œì¤€ í•™ê³¼ëª…'ì„ ê°€ì§„ Major ë ˆì½”ë“œë¥¼ ì¡°íšŒ
            vector_records = (
                db.query(Major).filter(Major.major_name.in_(vector_matched_names)).all()
            )

            existing_ids = {r.id for r in major_records}
            for vr in vector_records:
                if vr.id not in existing_ids:
                    major_records.append(vr)
                    existing_ids.add(vr.id)

        # =========================================================
        # 3. ëŒ€í•™ ì •ë³´ íŒŒì‹± ë° ì¶”ì¶œ
        # =========================================================
        for record in major_records:
            if not record.university:
                continue

            try:
                # JSON ì»¬ëŸ¼ íŒŒì‹± (record.universityëŠ” LONGTEXTë¡œ ì €ì¥ëœ JSON string)
                univ_list = json.loads(record.university)
                if not isinstance(univ_list, list):
                    continue

                for item in univ_list:
                    school = (item.get("schoolName") or "").strip()
                    major_name = (item.get("majorName") or "").strip()
                    campus = (
                        item.get("campus_nm") or item.get("campusNm") or ""
                    ).strip()
                    area = (item.get("area") or "").strip()
                    url = (item.get("schoolURL") or "").strip()

                    if not school:
                        continue

                    # í•™ê³¼ëª…ì´ ë¹„ì–´ìˆìœ¼ë©´ í‘œì¤€ í•™ê³¼ëª… ì‚¬ìš©
                    dept_label = major_name if major_name else record.major_name

                    # ì¤‘ë³µ ì œê±° (ëŒ€í•™, í•™ê³¼, ìº í¼ìŠ¤)
                    dedup_key = (school, dept_label, campus)
                    if dedup_key in seen:
                        continue
                    seen.add(dedup_key)

                    entry = {
                        "university": school,
                        "college": campus or area or "",
                        "department": dept_label,
                        "url": url,
                        "standard_major_name": record.major_name,
                    }
                    if area:
                        entry["area"] = area
                    if campus:
                        entry["campus"] = campus

                    aggregated.append(entry)

            except json.JSONDecodeError:
                print(f"âš ï¸  JSON Decode Error in Major ID {record.id}")
                continue

    except Exception as e:
        print(f"âŒ SQL Query Error: {e}")
        _log_tool_result("get_universities_by_department", f"SQL Error: {e}")
        return [
            {
                "error": "db_error",
                "message": "ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            }
        ]
    finally:
        db.close()

    # ê²°ê³¼ ì œí•œ
    MAX_UNIVERSITY_RESULTS = 1000  # ê²€ìƒ‰ ê²°ê³¼ ìµœëŒ€ ê°œìˆ˜
    aggregated = aggregated[:MAX_UNIVERSITY_RESULTS]

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if not aggregated:
        print(f"âš ï¸  WARNING: No universities found offering '{query}' in SQL DB")
        result = [
            {
                "error": "no_results",
                "message": f"'{query}' í•™ê³¼ë¥¼ ê°œì„¤í•œ ëŒ€í•™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "suggestion": "í•™ê³¼ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ê±°ë‚˜ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.",
            }
        ]
        _log_tool_result("get_universities_by_department", "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ì˜¤ë¥˜ ë°˜í™˜")
        return result

    _log_tool_result(
        "get_universities_by_department",
        f"ì´ {len(aggregated)}ê±´ ëŒ€í•™ ì •ë³´ ë°˜í™˜ (SQL Source)",
    )
    print(f"âœ… Retrieved {len(aggregated)} universities for '{query}'")
    return aggregated


@tool
def get_search_help() -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•  ì ì ˆí•œ íˆ´ì„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜, ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ë„ì›€ë§ì„ ì œê³µí•˜ëŠ” íˆ´ì…ë‹ˆë‹¤.

    ì´ íˆ´ì„ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” ìƒí™© (LLMìš© ê°€ì´ë“œ):
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë„ˆë¬´ ëª¨í˜¸í•˜ì—¬ ì–´ë–¤ íˆ´ì„ ì¨ì•¼ í• ì§€ íŒë‹¨ì´ ì„œì§€ ì•Šì„ ë•Œ
    - ë‹¤ë¥¸ íˆ´ì„ í˜¸ì¶œí–ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆì–´("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"), ì‚¬ìš©ìì—ê²Œ ê²€ìƒ‰ íŒì„ ì¤˜ì•¼ í•  ë•Œ
    - ì‚¬ìš©ìê°€ "ì–´ë–»ê²Œ ê²€ìƒ‰í•´ì•¼ í•´?", "ë„ì›€ë§ ë³´ì—¬ì¤˜"ë¼ê³  ì§ì ‘ ìš”ì²­í•  ë•Œ

    ì´ íˆ´ì€ ë³„ë„ì˜ íŒŒë¼ë¯¸í„° ì—†ì´ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤.
    """
    _log_tool_start("get_search_help", "ê²€ìƒ‰ ê°€ì´ë“œ ì•ˆë‚´")
    print("â„¹ï¸  Using get_search_help tool - providing usage guide to user")

    message = _get_tool_usage_guide()

    _log_tool_result("get_search_help", "ì‚¬ìš©ì ê°€ì´ë“œ ë©”ì‹œì§€ ë°˜í™˜")
    return message


@tool
def get_university_admission_info(university_name: str) -> Dict[str, Any]:
    """
    íŠ¹ì • ëŒ€í•™ì˜ 'ì…ì‹œ(ì…í•™) ì •ë³´'ë¥¼ ì¡°íšŒí•˜ëŠ” íˆ´ì…ë‹ˆë‹¤.
    ìˆ˜ì‹œ/ì •ì‹œ ë“±ê¸‰ ì»·, ê²½ìŸë¥ , ëª¨ì§‘ ìš”ê°• ë“± 'ëŒ€í•™ ì…í•™'ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œ ì œê³µí•©ë‹ˆë‹¤.

    [í˜¸ì¶œ ì‹œì ]
    - ì‚¬ìš©ìê°€ "ì„œìš¸ëŒ€ ì»´ê³µ ì •ì‹œì»·", "ì—°ì„¸ëŒ€ ìˆ˜ì‹œ ë“±ê¸‰" ë“± **ì…ì‹œ/ì…í•™** ì •ë³´ë¥¼ ë¬¼ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
    - ì…ë ¥ìœ¼ë¡œ ë°›ì€ ëŒ€í•™ëª…ë§Œ ì‚¬ìš©í•˜ë©°, í•™ê³¼ëª…ì€ ë¬´ì‹œí•©ë‹ˆë‹¤.

    [ì£¼ì˜ - ì‚¬ìš© ê¸ˆì§€ ì¼€ì´ìŠ¤]
    - **ì·¨ì—…ë¥ , ì—°ë´‰, ì§„ë¡œ, ì¡¸ì—… í›„ ì§ì—…** ë“± ì¡¸ì—… í›„ ì •ë³´ëŠ” ì´ íˆ´ì—ì„œ ì ˆëŒ€ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
      ì´ ê²½ìš° ëŒ€í•™ëª…ì´ í¬í•¨ë˜ì–´ ìˆì–´ë„ ë¬´ì¡°ê±´ `get_major_career_info`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

    íŒŒë¼ë¯¸í„° ì„¤ëª…:
    - university_name:
        ì…ì‹œ ì •ë³´ë¥¼ ì¡°íšŒí•  ëŒ€í•™ëª….
        ì˜ˆ: "ì„œìš¸ëŒ€í•™êµ", "ì—°ì„¸ëŒ€í•™êµ", "ê³ ë ¤ëŒ€í•™êµ"
    """
    query = (university_name or "").strip()

    _log_tool_start(
        "get_university_admission_info",
        f"ëŒ€í•™ ì…ì‹œ ì •ë³´ ì¡°íšŒ - university='{query}'",
    )
    print(f"âœ… Using get_university_admission_info tool for: '{query}'")

    # ì…ë ¥ ê²€ì¦
    if not query:
        result = {
            "error": "invalid_query",
            "message": "ëŒ€í•™ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
            "suggestion": "ì˜ˆ: 'ì„œìš¸ëŒ€í•™êµ', 'ì—°ì„¸ëŒ€í•™êµ', 'ê³ ë ¤ëŒ€í•™êµ'",
        }
        _log_tool_result("get_university_admission_info", "ëŒ€í•™ëª… ëˆ„ë½ - ì˜¤ë¥˜ ë°˜í™˜")
        return result

    # ëŒ€í•™ ì •ë³´ ì¡°íšŒ
    university_info = lookup_university_url(query)

    # ëŒ€í•™ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
    if university_info is None:
        print(f"âš ï¸  WARNING: No admission data found for '{query}'")
        similar_universities = search_universities(query)
        if similar_universities:
            similar_names = [u["university"] for u in similar_universities[:5]]
            result = {
                "error": "no_exact_match",
                "message": f"'{query}' ëŒ€í•™ì˜ ì…ì‹œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "suggestion": f"ë‹¤ìŒ ëŒ€í•™ëª… ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”: {', '.join(similar_names)}",
                "similar_universities": similar_names,
            }
        else:
            result = {
                "error": "no_results",
                "message": f"'{query}' ëŒ€í•™ì˜ ì…ì‹œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "suggestion": "ëŒ€í•™ëª…ì„ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: 'ì„œìš¸ëŒ€í•™êµ', 'ì—°ì„¸ëŒ€í•™êµ[ë³¸êµ]'",
            }
        _log_tool_result(
            "get_university_admission_info", "ëŒ€í•™ ë°ì´í„° ë¯¸ë°œê²¬ - ì˜¤ë¥˜ ë°˜í™˜"
        )
        return result

    # ê°„ë‹¨í•œ ê²°ê³¼ ë°˜í™˜ (í•™ê³¼ ë¡œì§ ì œê±°)
    result = {
        "university": university_info["university"],
        "url": university_info.get("url", ""),
        "message": (
            f"'{university_info['university']}'ì˜ ì…ì‹œ ì •ë³´ëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            "ì„¸ë¶€ í•™ê³¼ì— ëŒ€í•œ ëª¨ì§‘ ìš”ê°• ë° ì…ì‹œ ê²°ê³¼ëŠ” í•´ë‹¹ ì…í•™ì²˜ í™ˆí˜ì´ì§€ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”."
        ),
    }

    _log_tool_result(
        "get_university_admission_info",
        f"ëŒ€í•™ ì…ì‹œ URL ë°˜í™˜: {university_info.get('url')}",
    )
    return result
